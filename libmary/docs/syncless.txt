Минимизация использования примитивов синхронизации в Moment. Syncless code.

Первый шаг к упрощению синхронизации - домены синхронизации. Это гарантии
синхронизации для группы методов или колбэков одного объекта.

Второй шаг - привязка объектов к потокам. Это позволяет более полно использовать
домены синхронизации, т к теперь код, выполняемый в десткрукторах, тоже может
быть отнесён к конкретному домену.

Слабым местом остаются цепочки вызовов, в которых перед каждым вызовм
выполняется операция getRef(). Я попробовал сгладить этот эффект с помощью
last_coderef_container, но, думаю, этого недостаточно.

Основная цель getRef() - "зацепить" объект, не допуская его удаления в течение
нкоторого короткого промежутка времени. Есть ли другие способы добиться
того же эффекта?

Один из вариантов - stop the world collection. Точнее, stop-the-world атомарное
зануление слабых ссылок. Суть getRef() в том, чтобы захватить мьютекс shadow,
увеличить счётчик ссылок объекта и освободить мьютекс. Stop-the-world зануление
позволяет избежать необходимости захватывать мьютекс, т е остаётся только
увеличение счётчика ссылок.

Следующий момент - stop-the-world удаление объектов. Это позволяет избежать
необходимости делать явные временные ссылки на объекты, т к теперь заранее
известно, что объект останется "жив", пока вызывается любой из его методов.

Есть два основных способа взаимодействия с объектами. Первый - прямой вызов
асинхронного метода объекта. При этом состояние объекта синхронизируется
с помощью отдельного мьютекса. Второй способ - посылка сообщения объекту.
При этом сообщение обрабатывается в потоке, к которому привязан объект.

Отправку сообщений из одного потока в другой можно выполнять большими группами
в конце каждой итерации цикла обработки сообщений: обрабатываем сообщения,
получаем очередь из сообщений для других потоков, одномоментно передаём
все сообщения потокам-адресатам.

Мьютексы и домены синхронизации разрывают состояние объекта на две части:
асинхронную и синхронную. При этом асинхронные методы не могут напрямую работать
с синхронными данными объекта. Синхронные методы, наоборот, могут работать
с асинхронными данными при условии захвата мьютекса состояния объекта.
Такое разделение позволяет говорить о разделении объекта на два самостоятельных
подъобъекта: синхронный и асинхронный.

Подсчёт ссылок тоже можно организовать через привязку к потокам: операции
увеличения/уменьшения счётчиков ссылок передавать в поток, к которому привязан
объект.

Наибольшее значение имеет подсчёт ссылок на часто используемые объекты.
Например, страницы из пула страниц. Они используются одновременно в разных
потоках, в больших количествах. Помимо освобождения, страницы нужно ещё и
получать из пула. Один из вариантов - получать страницы из субпула, привязанного
к текущему потоку. Жизнеспособный вариант. Если освобождение страниц
выполнять отправкой сообщений о декрементах, то получим при рассылке 1->1000
тысяцу сообщений о декременте, или 8 Кб данных на одну 4 Кб страницу - очень
неэффективно. Гораздо интереснее было бы иметь возможность "склеивать"
декременты, выполненные в одном и том же потоке за текущую итерацию.

1 страница, 8 потоков => 8 * 8 = 64 байта на подсчёт ссылок с раздельными
счётчиками для каждого потока. Расточительно и не масштабируется.
Можно складывать объекты, кол-во ссылок на которые изменилось, в thread-local
хэш, чтобы обновлять кол-во ссылок в одном месте.

8 байт, хэш на 2 байта, выравнивание 8 байт, т е получаем 2**(64 - 8 - 16) =
2**40 макс объектов на ячейку. Т е реально ограничивается логикой приложения.
Если расклад по хэшу хороший, то получаем *65536 ускорение. На это расходуется
512 Кб памяти. В 32 Кб можно уместить ускорение *4096, что тоже неплохо.
32 * 4096 = 131072 (мин одна 4 Кб страница на каждую ячейку хэша).

Нужо экспериментально оценить эти схемы на Core i7. Сценарии для имитации -
раздача данных один ко многим и один к одному с разными схемами синхронизации.
У меня есть сомнения, что synchronization domains - это такая уж хорошая
оптимизация.

Простой тест. В одном потоке генерируется N страниц, затем эти страницы
поочереди записываются через write() в /dev/null. На пути write()
устанавливаем N прокси-объектов, при вызове методов которых
используется синхронизация. Смотрим, как длина цепочки влияет на скорость
записи.

Тест syncbench показал, что операции синхронизации довольно дороги. Замедление
до четырёх раз при вполне реальном для moment кол-ве операций синхронизации
на одну посылку.

