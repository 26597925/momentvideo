13.11.08 Управление памятью в moment.

Текущие проблемы:
  * Непредсказуемое потребление памяти в gstreamer.
    Перекодирование одного потока x264 со временем съедает до 1 Гб памяти
    (в несколько итераций перезапуска источника);
  * Механизм PagePool::Page неэффективен.
  * Потребление памяти FrameSaver'ами плохо проработано и не лимитировано.

Основная проблема - полное отсутствие доверия к gstreamer'у. Не позволяет
заявить уверенную поддержку многих источников. Что с этим делать?
    а) отказаться от gstreamer, писать собственную реализацию захвата.
           - gstreamer важен только для live-каналов, т е фактически
             польза от его применения весьма ограничена;
           - перекодирование Speex в AAC можно реализовать и без помощи
             gstreamer.
    б) отлаживать и дорабатывать gstreamer;
           - нахожу это непрактичным. GStreamer переусложнён и неудачен.
             В нём много ошибок, критичных для работы видеосервера
             как целого. В новых версиях появляются новые ошибки:
             я с этим сталкивался неоднократно. Другими словами, это
             PITA, от которой очень хочется избавиться.
    в) загнать gstreamer в песочницу и запускать отдельным потоком.
           - возможно, самый разумный подход. Этому софту я не доверяю
             _совершенно_. Выделение в отдельный процесс обеспечит
             достаточную изоляцию gstreamer'а, полное освобождение
             памяти при переключении, и т п.
             Это особенно актуально в свете того, что взаимодействие
             с gstreamer'ом свелось к построению конвейеров в текстовой
             форме и их исполнению. Вынесение в отдельный процесс
             на этом фоне - совершенно естественное действие.
             ...заодно решится вопрос о рассылке данных в потоке
             перекодирования: рассылка станет явно раздельной.

Следовательно, очередная задача - вынести работу с gstreamer'ом в отдельные процессы.

Надеяться на отсутствие утечек в коде перекодирования при инициализации/деинициализации -
более чем наивно. В x.264 утечки _есть_ и _появляются/исчезают_ в новых версиях.
Невозможно построить надёжный продукт, не изолировав сложную логику работы с видеоданными
в отдельные процессы (если, конечно, это не полностью моя логика).

---

15.09.03 Оптимизация управления памятью.

Темы для изучения:
    1. Насколько оправдано применение мезанизма PagePool вообще?
    2. Можно ли абстрагировать управление памятью таким образом, чтобы можно
       было переключаться между использованием PagePool и прямым выделением
       непрерывных блоков памяти?
    3. Можно ли оптимизировать размещение потоковых данных в страницах?
       Если да, то какой выигрыш можно от этого получить?

PagePool обладает рядом явных недостатков:
    * примитивная синхронизация глобальной блокировкой;
    * размещение даже маленького аудиосообщения в отдельной 4 КБ странице;
    * необходимость следить за ссылками на страницы;
    * постоянное притягивание ссылки на сам PagePool.

Системный аллокатор:
    * может быть эффективнее при работе в несколько потоков;
    * выделяет сразу крупные блоки;
    * может страдать от фрагментации на 32бит, но на 64бит,
      скорее всего, будет работать совершенно нормально;
    * выделяет непрерывные участки памяти (эффективнее кеши).

getFillPages() - сильная абстрация, упрощающая написание кода заполнения
сообщений данными. Можно ли обойтись без неё?

3 идеи:
    1) типы страниц - страницы могут быть разнородными,
       некоторые из них управляются стандартным аллокатором;
    2) отделить состояние отправки SenderMessageEntry от
       описания SenderMessageEntry, и выделять состояние отправки
       в буфере, привязанном к Sender'у;
    3) выделять страницы в потоковом режиме, когда страницы
       следующего сообщения совмещаются со страницами предыдущего.

Получается, что в случае разнородных страниц концепции страниц и описания сообщения
начинают пересекаться. - Нет, т к описание сообщения - это метод  формирования
векторов для отправки сообщения.

Фактически получается, что эффективнее реализовать "1" и "2" в рамках одного
класса PagePool, добавив в него возможность выделения страниц меньшего размера
и/или выделения буферов произвольного размера.

Как протестировать эффективность PagePool? Меня интересует эффективность
в определённом сценарии загрузки сервера. Данных mstat будет не хватать.

Принципу простоты и прямолинейности удовлетворяет только идея "3". Идея "2" - это
слабо связанная с ней оптимизация. От "1" отказываюсь. Определять размер сообщения
заранее - полензная практика: это позволило бы существенно уменьшить contention
при заполнении сложных сообщений (с множественными вызовами getFillPages).

! Ещё одна текущая проблема PagePool - повторяющаяся синхронизация из-за
идущих подряд вызовов getFillPages(). Отчасти это - недостаток API.
При исправлении этого недостатка можно API сформировать таким образом, чтобы
можно было протестировать замещение всех цепочек страниц выделенными буферами
произвольного размера.

Т е одновременно с оптимизацией работы со страницами нужно попробовать найти
вариант интерфейса, который позволил бы полностью убрать зависимость от страничной
организации данных видеопотока.

